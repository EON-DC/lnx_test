{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIGURATION = {\n",
    "    \"IMAGE_HEIGHT\": 160,  # 224 -> 160으로 축소 (계산량 50% 감소)\n",
    "    \"IMAGE_WIDTH\": 160,\n",
    "    \"BATCH_SIZE\": 64,  # 32 -> 64로 증가 (GPU 메모리 활용)\n",
    "    \"EPOCHS\": 20,  # 30 -> 20으로 감소 (EarlyStopping으로 조기 종료)\n",
    "    \"LEARNING_RATE\": 0.001,\n",
    "    \"NUM_CLASSES\": 31,\n",
    "    \"DROPOUT_RATE\": 0.3,  # 0.4 -> 0.3으로 감소\n",
    "    \"PATIENCE\": 3,  # 5 -> 3으로 단축\n",
    "    \"VALIDATION_SPLIT\": 0.2,\n",
    "    \"TRAIN_CSV\": \"dataset/train.csv\",\n",
    "    \"TRAIN_IMAGE_DIR\": \"dataset/train/train\",\n",
    "    \"TEST_CSV\": \"dataset/test.csv\",\n",
    "    \"TEST_IMAGE_DIR\": \"dataset/test/test\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### PREPROCESSING\n",
    "kaggle에서 다운로드한 데이터는 train.csv 와 train/train/\\[images\\].png 형태로 구분됨.\n",
    "따라서, dataset으로 구성하기 위해서, paths와 labels 파싱하여\n",
    "tf.data.Dataset.from_tensor_slices((paths, labels))를 구성한다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train csv 에서 ground_truth 불러오기\n",
    "train_csv_path = pathlib.Path(CONFIGURATION[\"TRAIN_CSV\"])\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "test_csv_path = pathlib.Path(CONFIGURATION[\"TEST_CSV\"])\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "jaguar_names = train_df[\"ground_truth\"].unique()\n",
    "print(f\"Shape of training data: {train_df.shape}\")\n",
    "print(f\"Shape of testing data: {test_df.shape}\")\n",
    "print(f\"Number of unique jaguar identities: {len(jaguar_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_set_dir = pathlib.Path(CONFIGURATION[\"TRAIN_IMAGE_DIR\"])\n",
    "test_image_set_dir = pathlib.Path(CONFIGURATION[\"TEST_IMAGE_DIR\"])\n",
    "existing_train = set(os.listdir(train_image_set_dir))\n",
    "existing_test = set(os.listdir(test_image_set_dir))\n",
    "print(f\"Number of training images: {len(existing_train)}\")\n",
    "print(f\"Number of testing images: {len(existing_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 클래스별 샘플 수 분석\n",
    "class_distribution = train_df[\"ground_truth\"].value_counts()\n",
    "print(\"\\n클래스별 샘플 분포:\")\n",
    "print(class_distribution)\n",
    "print(f\"\\n평균 샘플 수: {class_distribution.mean():.2f}\")\n",
    "print(f\"최대: {class_distribution.max()}, 최소: {class_distribution.min()}\")\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(12, 6))\n",
    "class_distribution.plot(kind=\"bar\")\n",
    "plt.title(\"Class Distribution in Training Dataset\")\n",
    "plt.xlabel(\"Jaguar Identity\")\n",
    "plt.ylabel(\"Number of Samples\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df[train_df[\"filename\"].isin(existing_train)].copy()\n",
    "df[\"path\"] = df[\"filename\"].apply(lambda x: os.path.join(train_image_set_dir, x))\n",
    "class_names = sorted(df[\"ground_truth\"].unique().tolist())\n",
    "lookup = keras.layers.StringLookup(vocabulary=class_names, num_oov_indices=0)\n",
    "paths = df[\"path\"].tolist()\n",
    "labels = df[\"ground_truth\"].astype(str).tolist()\n",
    "ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "\n",
    "# 데이터 증강 파이프라인\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.1),\n",
    "        layers.RandomContrast(0.1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def process_path(file_path, label):\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(\n",
    "        img, [CONFIGURATION[\"IMAGE_HEIGHT\"], CONFIGURATION[\"IMAGE_WIDTH\"]]\n",
    "    )\n",
    "    img = img / 255.0\n",
    "    label = lookup(label)\n",
    "    return img, label\n",
    "\n",
    "\n",
    "def augment_path(img, label):\n",
    "    img = data_augmentation(img, training=True)\n",
    "    return img, label\n",
    "\n",
    "\n",
    "ds = ds.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds = ds.shuffle(buffer_size=len(df))\n",
    "\n",
    "# 데이터 증강은 학습 데이터에만 적용\n",
    "train_size = int((1 - CONFIGURATION[\"VALIDATION_SPLIT\"]) * len(df))\n",
    "train_ds = ds.take(train_size)\n",
    "val_ds = ds.skip(train_size)\n",
    "\n",
    "train_ds = train_ds.map(augment_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_ds = train_ds.batch(CONFIGURATION[\"BATCH_SIZE\"]).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.batch(CONFIGURATION[\"BATCH_SIZE\"]).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# 개선된 모델 아키텍처 (Dropout + BatchNormalization)\n",
    "model = models.Sequential(\n",
    "    [\n",
    "        layers.InputLayer(\n",
    "            input_shape=(CONFIGURATION[\"IMAGE_HEIGHT\"], CONFIGURATION[\"IMAGE_WIDTH\"], 3)\n",
    "        ),\n",
    "        layers.Conv2D(32, (3, 3), activation=\"relu\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(CONFIGURATION[\"DROPOUT_RATE\"]),\n",
    "        layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(CONFIGURATION[\"DROPOUT_RATE\"]),\n",
    "        layers.Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(CONFIGURATION[\"DROPOUT_RATE\"]),\n",
    "        layers.Conv2D(256, (3, 3), activation=\"relu\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(CONFIGURATION[\"DROPOUT_RATE\"]),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(512, activation=\"relu\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(CONFIGURATION[\"DROPOUT_RATE\"]),\n",
    "        layers.Dense(CONFIGURATION[\"NUM_CLASSES\"], activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=CONFIGURATION[\"LEARNING_RATE\"]),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 콜백 설정\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=CONFIGURATION[\"PATIENCE\"],\n",
    "    restore_best_weights=True,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-6, verbose=1\n",
    ")\n",
    "\n",
    "model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    \"jaguar_reid_best_model.h5\", monitor=\"val_accuracy\", save_best_only=True, verbose=1\n",
    ")\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=CONFIGURATION[\"EPOCHS\"],\n",
    "    callbacks=[early_stopping, reduce_lr, model_checkpoint],\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "model.save(\"jaguar_reid_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### history 그래프 그리기\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history[\"accuracy\"], label=\"Train Accuracy\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
    "plt.title(\"Accuracy over Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.title(\"Loss over Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluate on test set with detailed metrics\n",
    "test_df_filtered = test_df[test_df[\"filename\"].isin(existing_test)].copy()\n",
    "test_df_filtered[\"path\"] = test_df_filtered[\"filename\"].apply(\n",
    "    lambda x: os.path.join(test_image_set_dir, x)\n",
    ")\n",
    "test_paths = test_df_filtered[\"path\"].tolist()\n",
    "test_labels = test_df_filtered[\"ground_truth\"].astype(str).tolist()\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_paths, test_labels))\n",
    "test_ds = test_ds.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.batch(CONFIGURATION[\"BATCH_SIZE\"]).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_ds, verbose=0)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# 상세 평가 지표 (Classification Report)\n",
    "y_pred_list = []\n",
    "y_true_list = []\n",
    "\n",
    "for images, labels in test_ds:\n",
    "    predictions = model.predict(images, verbose=0)\n",
    "    y_pred_list.extend(np.argmax(predictions, axis=1))\n",
    "    y_true_list.extend(labels.numpy())\n",
    "\n",
    "y_pred_array = np.array(y_pred_list)\n",
    "y_true_array = np.array(y_true_list)\n",
    "\n",
    "# 클래스별 성능 지표\n",
    "print(\"\\n=== Classification Report ===\")\n",
    "print(\n",
    "    classification_report(\n",
    "        y_true_array, y_pred_array, target_names=class_names, digits=4\n",
    "    )\n",
    ")\n",
    "\n",
    "# 혼동 행렬 시각화\n",
    "cm = confusion_matrix(y_true_array, y_pred_array)\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=False,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=class_names,\n",
    "    yticklabels=class_names,\n",
    ")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 클래스별 정확도\n",
    "per_class_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
    "print(\"\\n=== Per-Class Accuracy ===\")\n",
    "for class_name, acc in zip(class_names, per_class_accuracy):\n",
    "    print(f\"{class_name}: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 테스트 이미지 예측 시각화\n",
    "def visualize_predictions(model, test_ds, num_samples=12):\n",
    "    \"\"\"테스트 셋에서 예측 결과를 시각화합니다.\"\"\"\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    sample_count = 0\n",
    "    for images, labels in test_ds:\n",
    "        for i in range(len(images)):\n",
    "            if sample_count >= num_samples:\n",
    "                break\n",
    "\n",
    "            img = images[i].numpy()\n",
    "            true_label_idx = labels[i].numpy()\n",
    "            true_label = class_names[true_label_idx]\n",
    "\n",
    "            # 예측\n",
    "            prediction = model.predict(np.expand_dims(img, axis=0), verbose=0)\n",
    "            pred_label_idx = np.argmax(prediction[0])\n",
    "            pred_label = class_names[pred_label_idx]\n",
    "            confidence = np.max(prediction[0])\n",
    "\n",
    "            # 시각화\n",
    "            plt.subplot(3, 4, sample_count + 1)\n",
    "            plt.imshow(img)\n",
    "            color = \"green\" if true_label == pred_label else \"red\"\n",
    "            plt.title(\n",
    "                f\"True: {true_label}\\nPred: {pred_label}\\nConf: {confidence:.2f}\",\n",
    "                color=color,\n",
    "            )\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "            sample_count += 1\n",
    "\n",
    "        if sample_count >= num_samples:\n",
    "            break\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "visualize_predictions(model, test_ds, num_samples=12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf220",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
