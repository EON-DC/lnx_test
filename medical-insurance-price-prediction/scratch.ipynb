{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from keras.layers import Layer, BatchNormalization, Activation, InputLayer\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import CategoricalAccuracy, TopKCategoricalAccuracy\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.regularizers import L2, L1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\n",
    "    \"harishkumardatalab/medical-insurance-price-prediction\"\n",
    ")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(path)\n",
    "csv_name = \"Medical_insurance.csv\"\n",
    "\n",
    "dataset_path = Path.joinpath(root, csv_name)\n",
    "print(\"다운로드 경로:\", dataset_path)\n",
    "\n",
    "df = pd.read_csv(dataset_path)\n",
    "display(df.head())\n",
    "display(df.shape)\n",
    "display(df.isnull().value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(df[df.columns], diag_kind=\"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [\"sex\", \"region\", \"smoker\"]\n",
    "\n",
    "# one hot encoding\n",
    "df_onehot_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=False)\n",
    "display(\"after : one hot encoding\")\n",
    "display(df_onehot_encoded.head())\n",
    "\n",
    "# column 정렬 (charges 맨 뒤로)\n",
    "col_charges = df_onehot_encoded[\"charges\"]\n",
    "df_onehot_encoded = df_onehot_encoded.drop(columns=[\"charges\"])\n",
    "df_onehot_encoded = pd.concat([df_onehot_encoded, col_charges], axis=1)\n",
    "display(\"after : column 재정의\")\n",
    "display(df_onehot_encoded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIGURATION = {\n",
    "    \"TRAIN_RATIO\": 0.7,\n",
    "    \"VAL_RATIO\": 0.15,\n",
    "    \"TEST_RATIO\": 0.15,\n",
    "    \"RANDOM_SEED\": 44,\n",
    "    \"SHUFFLE\": True,\n",
    "    \"BATCH_SIZE\": 32,\n",
    "    \"EPOCHS\": 100,\n",
    "    \"INITIAL_LEARNING_RATE\": 1e-3,\n",
    "    \"PATIENCE\": 10,\n",
    "}\n",
    "DATASET_SIZE = (len(df_onehot_encoded),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train, test\n",
    "df_onehot_encoded[\"charges\"] = np.log1p(df_onehot_encoded[\"charges\"].astype(\"float32\"))\n",
    "\n",
    "tensor_data = tf.constant(df_onehot_encoded, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_xy(tensor_data):\n",
    "    X = tensor_data[:, 0:-1]\n",
    "    y = tensor_data[:, -1]\n",
    "\n",
    "    display(f\"Shape of X: {X.shape}\")\n",
    "    display(f\"Shape of y: {y.shape}\")\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def make_datasets(X, y):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "    if CONFIGURATION[\"SHUFFLE\"]:\n",
    "        ds = ds.shuffle(buffer_size=len(y), seed=CONFIGURATION[\"RANDOM_SEED\"])\n",
    "\n",
    "    return ds.batch(CONFIGURATION[\"BATCH_SIZE\"]).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "\n",
    "def split_train_val_test(X, y):\n",
    "    total = int(X.shape[0])\n",
    "    val_n = int(total * CONFIGURATION[\"VAL_RATIO\"])\n",
    "    test_n = int(total * CONFIGURATION[\"TEST_RATIO\"])\n",
    "    train_n = total - val_n - test_n\n",
    "\n",
    "    X_train, y_train = X[:train_n], y[:train_n]\n",
    "    X_rest, y_rest = X[train_n:], y[train_n:]\n",
    "    X_val, y_val = X_rest[:val_n], y_rest[:val_n]\n",
    "    X_test, y_test = X_rest[val_n:], y_rest[val_n:]\n",
    "\n",
    "    train_ds = make_datasets(X_train, y_train)\n",
    "    val_ds = make_datasets(X_val, y_val)\n",
    "    test_ds = make_datasets(X_test, y_test)\n",
    "    return train_ds, val_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = split_xy(tensor_data)\n",
    "train_ds, val_ds, test_ds = split_train_val_test(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae_raw_from_log(y_true_log, y_pred_log):\n",
    "    y_true_raw = tf.math.expm1(y_true_log)\n",
    "    y_pred_raw = tf.math.expm1(y_pred_log)\n",
    "    y_pred_raw = tf.maximum(y_pred_raw, 0.0)\n",
    "    return tf.reduce_mean(tf.abs(y_true_raw - y_pred_raw))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Making Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = int(X.shape[1])\n",
    "\n",
    "inputs = keras.Input(shape=(D,), dtype=tf.float32)\n",
    "x = layers.Dense(128, activation=\"relu\")(inputs)\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "outputs = layers.Dense(1)(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=\"mse\",\n",
    "    metrics=[keras.metrics.MeanAbsoluteError(name=\"mae\")],\n",
    ")\n",
    "\n",
    "# 3) 학습\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.title(\"model loss\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"train\", \"val_loss\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_raw(model, ds):\n",
    "    y_pred = model.predict(ds)\n",
    "    return np.expm1(y_pred)\n",
    "\n",
    "\n",
    "def get_pred_eval(model, ds):\n",
    "    return model.evaluate(ds)\n",
    "\n",
    "\n",
    "def get_mae_rmse(y_pred, y_true):\n",
    "    mae = np.mean(np.abs(y_pred - y_true))\n",
    "    rmse = np.sqrt(np.mean((y_pred - y_true) ** 2))\n",
    "    return mae, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pred_eval(model, test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf220",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
