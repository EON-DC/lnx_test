{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras.layers import Layer, BatchNormalization, Activation, InputLayer\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from keras.layers import RandomContrast, RandomFlip, RandomRotation, RandomZoom\n",
    "from keras.layers import Concatenate, GlobalAveragePooling2D, GlobalMaxPooling2D\n",
    "from keras.layers import Resizing, Rescaling\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from keras.optimizers import Adam, AdamW, SGD\n",
    "from keras.metrics import CategoricalAccuracy, TopKCategoricalAccuracy\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.regularizers import L2, L1\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"dataset/Emotions Dataset/Emotions Dataset/train/\"\n",
    "test_dir = \"dataset/Emotions Dataset/Emotions Dataset/test/\"\n",
    "# check exist\n",
    "if os.path.exists(train_dir):\n",
    "    print(\"Training directory found.\")\n",
    "else:\n",
    "    print(\"Training directory not found.\")\n",
    "    raise FileNotFoundError(\"Training directory not found.\")\n",
    "if os.path.exists(test_dir):\n",
    "    print(\"Testing directory found.\")\n",
    "else:\n",
    "    print(\"Testing directory not found.\")\n",
    "    raise FileNotFoundError(\"Testing directory not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check images size\n",
    "# df_image_sizes = []\n",
    "# for class_name in os.listdir(train_dir):\n",
    "#     class_path = os.path.join(train_dir, class_name)\n",
    "#     if os.path.isdir(class_path):\n",
    "#         image_count = len(os.listdir(class_path))\n",
    "#         for i in range(image_count):\n",
    "#             sample_image_path = os.path.join(class_path, os.listdir(class_path)[i])\n",
    "#             sample_image = keras.preprocessing.image.load_img(sample_image_path)\n",
    "#             df_image_sizes.append(\n",
    "#                 {\n",
    "#                     \"class\": class_name,\n",
    "#                     \"width\": sample_image.size[0],\n",
    "#                     \"height\": sample_image.size[1],\n",
    "#                 }\n",
    "#             )\n",
    "# df_image_sizes = pd.DataFrame(df_image_sizes)\n",
    "# df_image_sizes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES = [\"angry\", \"happy\", \"sad\"]\n",
    "CONFIGURATION = {\n",
    "    \"IMAGE_SIZE\": 224,\n",
    "    \"BATCH_SIZE\": 64,\n",
    "    \"N_FILTERS\": 16,\n",
    "    \"KERNEL_SIZE\": 3,\n",
    "    \"N_STRIDES\": 4,\n",
    "    \"REGULATION_RATE\": 1e-3,\n",
    "    \"DROPOUT_RATE\": 0.4,\n",
    "    \"POOL_SIZE\": 2,\n",
    "    \"N_CLASSES\": len(CLASS_NAMES),\n",
    "    \"N_DENSE_1\": 2048,\n",
    "    \"N_DENSE_2\": 128,\n",
    "    \"EPOCHS\": 100,\n",
    "    \"INITIAL_LEARNING_RATE\": 1e-3,\n",
    "    \"DECAY_STEPS\": 500,\n",
    "    \"DECAY_RATE\": 0.95,\n",
    "    \"STAIRCASE\": True,\n",
    "    \"VALIDATION_SPLIT\": 0.01,\n",
    "    \"PATIENCE\": 10,\n",
    "    \"SEED\": 99,\n",
    "    \"DO_COMPILE\": True,\n",
    "    \"USING_MODEL_PATH\": \"best_lenet_model_acc85.keras\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=CLASS_NAMES,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=CONFIGURATION[\"BATCH_SIZE\"],\n",
    "    image_size=(CONFIGURATION[\"IMAGE_SIZE\"], CONFIGURATION[\"IMAGE_SIZE\"]),\n",
    "    shuffle=True,\n",
    "    seed=CONFIGURATION[\"SEED\"],\n",
    "    validation_split=CONFIGURATION[\"VALIDATION_SPLIT\"],\n",
    "    subset=\"training\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=CLASS_NAMES,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=CONFIGURATION[\"BATCH_SIZE\"],\n",
    "    image_size=(CONFIGURATION[\"IMAGE_SIZE\"], CONFIGURATION[\"IMAGE_SIZE\"]),\n",
    "    shuffle=True,\n",
    "    seed=CONFIGURATION[\"SEED\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 클래스의 샘플 수 확인\n",
    "for class_name in CLASS_NAMES:\n",
    "    class_path = os.path.join(train_dir, class_name)\n",
    "    count = len(os.listdir(class_path))\n",
    "    print(f\"{class_name}: {count} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스 불균형 해결\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    \"balanced\",\n",
    "    classes=np.array([0, 1, 2]),\n",
    "    y=np.array([0] * 1525 + [1] * 3019 + [2] * 2255),\n",
    ")\n",
    "class_weight_dict = {i: class_weights[i] for i in range(3)}\n",
    "\n",
    "# 학습 시 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in train_dataset.take(1):  # type: ignore\n",
    "#     images, labels = i\n",
    "#     print(images.shape)\n",
    "#     print(labels.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Dataset Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_dataset))\n",
    "print(\"Image batch shape: \", x.shape)\n",
    "print(\"Label batch shape: \", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = (\n",
    "    np.unique(y.numpy())\n",
    "    if len(y.shape) == 1\n",
    "    else np.unique(np.argmax(y.numpy(), axis=1))\n",
    ")\n",
    "print(\"unique labels:\", unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_training_history(history):\n",
    "    # plot training & validation accuracy values\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history[\"acc\"], label=\"Train Accuracy\")\n",
    "    plt.plot(history.history[\"val_acc\"], label=\"Validation Accuracy\")\n",
    "    plt.title(\"Model Accuracy\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    # plot training & validation loss values\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "    plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "    plt.title(\"Model Loss\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_dataset.take(1):  # type: ignore\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(f\"{CLASS_NAMES[tf.argmax(labels[i])]}(L:{labels[i].numpy()})\")\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = train_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)  # type: ignore\n",
    "validation_dataset = val_dataset.prefetch(buffer_size=tf.data.AUTOTUNE)  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_rescale_layers = keras.Sequential(\n",
    "    [\n",
    "        Resizing(CONFIGURATION[\"IMAGE_SIZE\"], CONFIGURATION[\"IMAGE_SIZE\"]),\n",
    "        Rescaling(1.0 / 255),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Data Augmentation 추가 (Dataset Preparation 직후)\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.25),\n",
    "        layers.RandomZoom(0.03),\n",
    "        layers.RandomContrast(0.1),\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")\n",
    "\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=CONFIGURATION[\"INITIAL_LEARNING_RATE\"],\n",
    "    decay_steps=CONFIGURATION[\"DECAY_STEPS\"],\n",
    "    decay_rate=CONFIGURATION[\"DECAY_RATE\"],\n",
    "    staircase=CONFIGURATION[\"STAIRCASE\"],\n",
    ")\n",
    "\n",
    "\n",
    "# optimizer = Adam(learning_rate=lr_schedule)\n",
    "# optimizer = AdamW(learning_rate=lr_schedule, weight_decay=1e-4)\n",
    "optimizer = SGD(learning_rate=lr_schedule, momentum=0.9, nesterov=True)\n",
    "\n",
    "loss = CategoricalCrossentropy(from_logits=False, label_smoothing=0.0)\n",
    "metrics = [\n",
    "    CategoricalAccuracy(name=\"acc\"),\n",
    "    CategoricalCrossentropy(name=\"cce\"),\n",
    "]\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=CONFIGURATION[\"PATIENCE\"],\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    \"best_lenet_model.keras\",\n",
    "    monitor=\"val_loss\",\n",
    "    save_best_only=True,\n",
    ")\n",
    "callbacks = [\n",
    "    early_stopping,\n",
    "    model_checkpoint,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_or_build_model():\n",
    "    if CONFIGURATION[\"DO_COMPILE\"]:\n",
    "        print(\"Model path not found. Building a new model.\")\n",
    "        loaded_model = _setup_lenet_model()\n",
    "    else:\n",
    "        if os.path.exists(CONFIGURATION[\"USING_MODEL_PATH\"]):\n",
    "            print(\"Loading model from:\", CONFIGURATION[\"USING_MODEL_PATH\"])\n",
    "            loaded_model = keras.models.load_model(CONFIGURATION[\"USING_MODEL_PATH\"])\n",
    "            return loaded_model\n",
    "        else:\n",
    "            raise FileNotFoundError(\"Model path not found.\")\n",
    "\n",
    "    # Build a new model if not loading\n",
    "    return loaded_model\n",
    "\n",
    "\n",
    "def _setup_lenet_model():\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            InputLayer((CONFIGURATION[\"IMAGE_SIZE\"], CONFIGURATION[\"IMAGE_SIZE\"], 3)),\n",
    "            resize_rescale_layers,\n",
    "            data_augmentation,\n",
    "            Conv2D(\n",
    "                filters=CONFIGURATION[\"N_FILTERS\"],\n",
    "                kernel_size=CONFIGURATION[\"KERNEL_SIZE\"],\n",
    "                padding=\"same\",\n",
    "                activation=\"relu\",\n",
    "                kernel_regularizer=L2(CONFIGURATION[\"REGULATION_RATE\"]),\n",
    "            ),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling2D(CONFIGURATION[\"POOL_SIZE\"], CONFIGURATION[\"N_STRIDES\"]),\n",
    "            Conv2D(\n",
    "                filters=CONFIGURATION[\"N_FILTERS\"] * 2,\n",
    "                kernel_size=CONFIGURATION[\"KERNEL_SIZE\"],\n",
    "                padding=\"same\",\n",
    "                activation=\"relu\",\n",
    "                kernel_regularizer=L2(CONFIGURATION[\"REGULATION_RATE\"]),\n",
    "            ),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling2D(CONFIGURATION[\"POOL_SIZE\"], CONFIGURATION[\"N_STRIDES\"]),\n",
    "            Conv2D(\n",
    "                filters=CONFIGURATION[\"N_FILTERS\"] * 8,\n",
    "                kernel_size=CONFIGURATION[\"KERNEL_SIZE\"],\n",
    "                padding=\"same\",\n",
    "                activation=\"relu\",\n",
    "                kernel_regularizer=L2(CONFIGURATION[\"REGULATION_RATE\"]),\n",
    "            ),\n",
    "            BatchNormalization(),\n",
    "            Dropout(CONFIGURATION[\"DROPOUT_RATE\"]),\n",
    "            Conv2D(\n",
    "                filters=CONFIGURATION[\"N_FILTERS\"] * 8,\n",
    "                kernel_size=CONFIGURATION[\"KERNEL_SIZE\"],\n",
    "                padding=\"same\",\n",
    "                activation=\"relu\",\n",
    "                kernel_regularizer=L2(CONFIGURATION[\"REGULATION_RATE\"]),\n",
    "            ),\n",
    "            BatchNormalization(),\n",
    "            Dropout(CONFIGURATION[\"DROPOUT_RATE\"]),\n",
    "            Conv2D(\n",
    "                filters=CONFIGURATION[\"N_FILTERS\"] * 8,\n",
    "                kernel_size=CONFIGURATION[\"KERNEL_SIZE\"],\n",
    "                padding=\"same\",\n",
    "                activation=\"relu\",\n",
    "                kernel_regularizer=L2(CONFIGURATION[\"REGULATION_RATE\"]),\n",
    "            ),\n",
    "            BatchNormalization(),\n",
    "            Flatten(),\n",
    "            Dense(\n",
    "                CONFIGURATION[\"N_DENSE_1\"],\n",
    "                activation=\"relu\",\n",
    "                kernel_regularizer=L2(CONFIGURATION[\"REGULATION_RATE\"]),\n",
    "            ),\n",
    "            Dropout(0.2),\n",
    "            Dense(\n",
    "                CONFIGURATION[\"N_DENSE_2\"],\n",
    "                activation=\"relu\",\n",
    "            ),\n",
    "            Dense(CONFIGURATION[\"N_CLASSES\"], activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "    model.compile(\n",
    "        optimizer=optimizer,  # type: ignore\n",
    "        loss=loss,\n",
    "        metrics=metrics,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "lenet_model = load_or_build_model()\n",
    "lenet_model.summary()\n",
    "print(lenet_model.output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # low loss test\n",
    "# y_true = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
    "# y_pred = np.array([[0.9, 0.05, 0.05], [0.1, 0.8, 0.1], [0.2, 0.2, 0.6]])\n",
    "# loss_value = loss(y_true, y_pred).numpy()\n",
    "# print(f\"Low loss value: {loss_value}\")\n",
    "\n",
    "# # high loss test\n",
    "# y_true = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
    "# y_pred = np.array([[0.1, 0.8, 0.1], [0.3, 0.01, 0.69], [0.9, 0.1, 0.0]])\n",
    "# loss_value = loss(y_true, y_pred).numpy()\n",
    "# print(f\"High loss value: {loss_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 만약 pass mode면 해당 셀에서 lenet_model 불러오기 빌드 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. 배치의 실제 이미지 범위 확인\n",
    "# # 2. 시각화하여 이미지가 올바른지 확인\n",
    "# plt.figure(figsize=(12, 3))\n",
    "# for images, labels in training_dataset.take(1):\n",
    "#     print(\"Image dtype:\", images.dtype)\n",
    "#     print(\"Image min:\", images.numpy().min())\n",
    "#     print(\"Image max:\", images.numpy().max())\n",
    "#     print(\"Label shape:\", labels.shape)\n",
    "#     print(\"Label sample:\", labels.numpy()[:3])\n",
    "#     print(\"Predicted class from label:\", np.argmax(labels.numpy()[:3], axis=1))\n",
    "#     for i in range(3):\n",
    "#         plt.subplot(1, 3, i + 1)\n",
    "#         img = images[i].numpy()\n",
    "#         if img.max() > 1:  # 0-255 범위\n",
    "#             img = img / 255.0\n",
    "#         plt.imshow(img.astype(\"float32\"))\n",
    "#         plt.title(CLASS_NAMES[np.argmax(labels[i].numpy())])\n",
    "#     break\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# small_ds = training_dataset.take(2).repeat()  # 배치 2개를 반복해서 외우게 함\n",
    "# history = lenet_model.fit(\n",
    "#     small_ds, steps_per_epoch=20, epochs=50, verbose=1, class_weight=class_weight_dict\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config 보고 load면 fit 패스\n",
    "if not CONFIGURATION[\"DO_COMPILE\"]:\n",
    "    print(\"Model loaded. Skipping training as per configuration.\")\n",
    "else:\n",
    "    print(\"Starting training...\")\n",
    "    history = lenet_model.fit(\n",
    "        training_dataset,\n",
    "        epochs=CONFIGURATION[\"EPOCHS\"],\n",
    "        validation_data=validation_dataset,\n",
    "        callbacks=callbacks,\n",
    "        # class_weight=class_weight_dict,\n",
    "        verbose=1,\n",
    "    )\n",
    "    visualize_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet_model.evaluate(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show false predictions\n",
    "plt.figure(figsize=(10, 10))\n",
    "i = 0\n",
    "for images, labels in validation_dataset:  # type: ignore\n",
    "    predictions = lenet_model.predict(images)\n",
    "    for j in range(len(images)):\n",
    "        if tf.argmax(predictions[j]) != tf.argmax(labels[j]):\n",
    "            ax = plt.subplot(3, 3, i + 1)\n",
    "            plt.imshow(images[j].numpy().astype(\"uint8\"))\n",
    "            plt.title(\n",
    "                f\"Predicted: {CLASS_NAMES[tf.argmax(predictions[j])]}, Actual: {CLASS_NAMES[tf.argmax(labels[j])]}\"\n",
    "            )\n",
    "            plt.axis(\"off\")\n",
    "            i += 1\n",
    "            if i >= 9:\n",
    "                break\n",
    "    if i >= 9:\n",
    "        break\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = []\n",
    "labels = []\n",
    "for images, label in validation_dataset:  # type: ignore\n",
    "    preds = lenet_model.predict(images, verbose=0)\n",
    "    predicted.extend(np.argmax(preds, axis=1).tolist())\n",
    "    labels.extend(np.argmax(label.numpy(), axis=1).tolist())\n",
    "\n",
    "cm = confusion_matrix(labels, predicted)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    xticklabels=CLASS_NAMES,\n",
    "    yticklabels=CLASS_NAMES,\n",
    "    cmap=\"Blues\",\n",
    ")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report_output = classification_report(\n",
    "    labels, predicted, target_names=CLASS_NAMES\n",
    ")\n",
    "print(\"Classification Report:\\n\", classification_report_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf220",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
